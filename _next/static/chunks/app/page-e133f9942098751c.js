(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[974],{5747:(e,t,a)=>{"use strict";a.d(t,{default:()=>N});var r=a(5155),s=a(2115);let l=e=>{let t=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,t,a)=>a?a.toUpperCase():t.toLowerCase());return t.charAt(0).toUpperCase()+t.slice(1)},c=function(){for(var e=arguments.length,t=Array(e),a=0;a<e;a++)t[a]=arguments[a];return t.filter((e,t,a)=>!!e&&""!==e.trim()&&a.indexOf(e)===t).join(" ").trim()};var i={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let n=(0,s.forwardRef)((e,t)=>{let{color:a="currentColor",size:r=24,strokeWidth:l=2,absoluteStrokeWidth:n,className:m="",children:o,iconNode:u,...d}=e;return(0,s.createElement)("svg",{ref:t,...i,width:r,height:r,stroke:a,strokeWidth:n?24*Number(l)/Number(r):l,className:c("lucide",m),...!o&&!(e=>{for(let t in e)if(t.startsWith("aria-")||"role"===t||"title"===t)return!0})(d)&&{"aria-hidden":"true"},...d},[...u.map(e=>{let[t,a]=e;return(0,s.createElement)(t,a)}),...Array.isArray(o)?o:[o]])}),m=(e,t)=>{let a=(0,s.forwardRef)((a,r)=>{let{className:i,...m}=a;return(0,s.createElement)(n,{ref:r,iconNode:t,className:c("lucide-".concat(l(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()),"lucide-".concat(e),i),...m})});return a.displayName=l(e),a},o=m("search",[["path",{d:"m21 21-4.34-4.34",key:"14j7rj"}],["circle",{cx:"11",cy:"11",r:"8",key:"4ej97u"}]]),u=m("rotate-ccw",[["path",{d:"M3 12a9 9 0 1 0 9-9 9.75 9.75 0 0 0-6.74 2.74L3 8",key:"1357e3"}],["path",{d:"M3 3v5h5",key:"1xhq8a"}]]),d=[{name:"GPT-OSS-20B-MXFP4 (llama.cpp)",description:"HF: bartowski/openai_gpt-oss-20b-GGUF-MXFP4-Experimental, ThinkLevel: medium - 運行約 1 小時半",category:"gpt-oss",hardware:"RTX4090",framework:"llama.cpp",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.4344,stderr:.0137},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.3397,stderr:.013}]},{name:"Gemma3-1B-IT-FP16 (ollama)",description:"ollama 官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"ollama",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.298,stderr:.0126},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.2024,stderr:.0111}]},{name:"Gemma3-4B-IT-FP16 (ollama)",description:"ollama 官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"ollama",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.6126,stderr:.0134},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.4602,stderr:.0137}]},{name:"Gemma3-12B-IT-FP16 (ollama)",description:"ollama 官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"ollama",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.8271,stderr:.0104},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.7968,stderr:.0111}]},{name:"Gemma3-27B-IT-QAT-Q4_0 (ollama)",description:"ollama 官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"ollama",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.859,stderr:.0096},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.8514,stderr:.0098}]},{name:"Gemma3n:E2B-IT-FP16 (ollama)",description:"ollama 官方儲存庫",category:"gemma3n",hardware:"RTX4090",framework:"ollama",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.6907,stderr:.0127},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.602,stderr:.0135}]},{name:"Gemma3n:E4B-IT-FP16 (ollama)",description:"ollama 官方儲存庫",category:"gemma3n",hardware:"RTX4090",framework:"ollama",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.7726,stderr:.0115},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.6763,stderr:.0129}]},{name:"GPT-OSS-20B-MXFP4 (ollama)",description:"ollama 官方儲存庫, MXFP4, ThinkLevel: medium - 運行約 1 小時",category:"gpt-oss",hardware:"RTX4090",framework:"ollama",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.395,stderr:.0135},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.1759,stderr:.0105}]},{name:"Llama-3-Taiwan-8B-Instruct-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"llama3",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.7376800606520091,stderr:.012116912419925704},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.6982562547384382,stderr:.012643544762873356},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.6487103174603175,stderr:.0032403073893666604},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.618,stderr:.0077206112668541365},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.6222348269994328,stderr:.011351445998177665},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.6275869784092181,stderr:.004954629551174923},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.706277274253105,stderr:.005753468936737745}]},{name:"Llama-3.1-TAIDE-LX-8B-Chat-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"llama3.1",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.1941,stderr:.0109},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:0,stderr:0},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.3866,stderr:.0034},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.354,stderr:.008},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.354,stderr:.0114},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.3978,stderr:.0051},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.4047,stderr:.0063}]},{name:"Gemma3-270M-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.01819560272934041,stderr:.0036816118940738705},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.012130401819560273,stderr:.0030152942428909395},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.2556051587301587,stderr:.00307431083242714},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.2557142857142857,stderr:.007383170100357892},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.2614861032331254,stderr:.010480863869935854},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.2596487302830294,stderr:.004639504861875137},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.24773413897280966,stderr:.005597285695169396}]},{name:"Gemma3-270M-IT-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.018953752843062926,stderr:.003756078341031473},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:0,stderr:0},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.25124007936507936,stderr:.003058923433973526},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.25485714285714284,stderr:.007379903664395711},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.25070901871809415,stderr:.010336250088913018},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.24924488197784986,stderr:.004580979422460125},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.25226586102719034,stderr:.0056341894020538255}]},{name:"Gemma3-1B-PT-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.02350265352539803,stderr:.004172883669643984},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.017437452615617893,stderr:.0036054868679982572},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.2536706349206349,stderr:.003067223514675123},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.248,stderr:.0073066838168183695},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.24787294384571754,stderr:.010292872668744832},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.25383152477905807,stderr:.004606655490553888},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.25847599865726756,stderr:.0056783771037919985}]},{name:"Gemma3-1B-IT-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.3153904473085671,stderr:.012799353675801836},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.2357846853677028,stderr:.0116925156506668},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.27232142857142855,stderr:.003129046095819468},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.2702857142857143,stderr:.00749314569360198},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.25921724333522406,stderr:.010445922718571544},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.26893388522206063,stderr:.004680603921898167},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.2824773413897281,stderr:.005818403123869934}]},{name:"Gemma3-4B-PT-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.37452615617892343,stderr:.013331774158491384},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.37225170583775585,stderr:.013315375362565038},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.3748015873015873,stderr:.003369815844399701},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.36942857142857144,stderr:.008079038279183059},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.32671582529778787,stderr:.011026563399222476},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.3660364694037364,stderr:.005051945632445054},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.405337361530715,stderr:.006276382491520932}]},{name:"Gemma3-4B-IT-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.7445034116755117,stderr:.012013462405460067},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.5784685367702805,stderr:.013601824409483263},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.30540674603174606,stderr:.0032293422469302567},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.30228571428571427,stderr:.007764817617012654},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.2665910380034033,stderr:.010543420822525719},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.3060745049781855,stderr:.004855723662601807},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.31772406847935547,stderr:.005982160599560892}]},{name:"Gemma3-12B-PT-bnb-nf4 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.66868840030326,stderr:.012964999679688666},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.6664139499620925,stderr:.012987282131410812},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.5263392857142857,stderr:.003426995492102798},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.5602857142857143,stderr:.008110951634378916},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.44639818491208166,stderr:.011622918182662131},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.4898758250363575,stderr:.005176661575741313},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.5847599865726754,stderr:.006293656738534028}]},{name:"Gemma3-12B-PT-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.7134192570128886,stderr:.012454841668337692},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.7088703563305534,stderr:.012513215297888463},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.5437996031746032,stderr:.0034168062314997014},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.5774285714285714,stderr:.008093402516412806},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.46511627906976744,stderr:.011687515479081883},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.5060968788455085,stderr:.005168849060718839},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.6038939241356159,stderr:.0062418093297851775}]},{name:"Gemma3-12B-IT-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3",hardware:"RTX5090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.8574677786201668,stderr:.009629588445673815},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.8233510235026535,stderr:.01050486250585457},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.5096726190476191,stderr:.003427063363036092},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.5334285714285715,stderr:.008166514597409105},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.39931934203062963,stderr:.011512192464280407},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.47701085132565163,stderr:.005157888322343281},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.5773749580396106,stderr:.006321750911863945}]},{name:"Gemma3-27B-IT-bnb-nf4 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.8855193328279,stderr:.008770157532110502},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.8726307808946171,stderr:.00918311032673783},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.5561011904761904,stderr:.0033992267193173505},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.5954285714285714,stderr:.00806478417739747},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.4271128757799206,stderr:.011585165719344918},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.5269045754558676,stderr:.005150389553926314},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.6149714669352132,stderr:.006195582434163899}]},{name:"Gemma3n:E2B-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3n",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.24109173616376042,stderr:.011782246325099714},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.2395754359363154,stderr:.01175686434407741},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.34910714285714284,stderr:.003321688044549879},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.33485714285714285,stderr:.007943342186850633},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.3091321610890527,stderr:.010971541772016001},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.340753999328784,stderr:.004961645818015982},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.3818395434709634,stderr:.006212689081384814}]},{name:"Gemma3n:E4B-IT-BF16 (huggingface)",description:"HuggingFace 模型官方儲存庫",category:"gemma3n",hardware:"RTX4090",framework:"huggingface",scores:[{task:"gsm8k",version:3,filter:"flexible-extract",nShot:5,metric:"exact_match",value:.711144806671721,stderr:.012484219800126671},{task:"gsm8k",version:3,filter:"strict-match",nShot:5,metric:"exact_match",value:.6391205458680819,stderr:.013228626753925141},{task:"tmmluplus",version:2,filter:"none",nShot:0,metric:"acc",value:.34305555555555556,stderr:.003308396763985619},{task:"tmmluplus_STEM",version:2,filter:"none",nShot:0,metric:"acc",value:.32457142857142857,stderr:.007900501536176255},{task:"tmmluplus_humanities",version:2,filter:"none",nShot:0,metric:"acc",value:.31310266591038005,stderr:.011011794095963508},{task:"tmmluplus_other",version:2,filter:"none",nShot:0,metric:"acc",value:.3344893164783533,stderr:.004949253583852297},{task:"tmmluplus_social_sciences",version:2,filter:"none",nShot:0,metric:"acc",value:.3756294058408862,stderr:.0061661873750182145}]}],h=e=>(100*e).toFixed(2)+"%",v={environment:{os:"Ubuntu 22.04",framework:"lm-evaluation-harness",primaryGpu:"RTX4090 24GB",secondaryGpu:"RTX5090 32GB"},benchmarks:{gsm8k:"Expert-written math benchmark covering multi-step elementary-level word problems (English), ~8,500 questions (7.5K train, 1K test).",tmmluplus:"Traditional Chinese multiple-choice cognitive benchmark, 66 domains (elementary to professional), ~22,690 questions, 6x larger and more balanced than original TMMLU."},license:{type:"MIT",copyright:"Copyright",year:"2025",holder:"Xuan-You Lin"}},x=m("trophy",[["path",{d:"M10 14.66v1.626a2 2 0 0 1-.976 1.696A5 5 0 0 0 7 21.978",key:"1n3hpd"}],["path",{d:"M14 14.66v1.626a2 2 0 0 0 .976 1.696A5 5 0 0 1 17 21.978",key:"rfe1zi"}],["path",{d:"M18 9h1.5a1 1 0 0 0 0-5H18",key:"7xy6bh"}],["path",{d:"M4 22h16",key:"57wxv0"}],["path",{d:"M6 9a6 6 0 0 0 12 0V3a1 1 0 0 0-1-1H7a1 1 0 0 0-1 1z",key:"1mhfuq"}],["path",{d:"M6 9H4.5a1 1 0 0 1 0-5H6",key:"tex48p"}]]),g=m("medal",[["path",{d:"M7.21 15 2.66 7.14a2 2 0 0 1 .13-2.2L4.4 2.8A2 2 0 0 1 6 2h12a2 2 0 0 1 1.6.8l1.6 2.14a2 2 0 0 1 .14 2.2L16.79 15",key:"143lza"}],["path",{d:"M11 12 5.12 2.2",key:"qhuxz6"}],["path",{d:"m13 12 5.88-9.8",key:"hbye0f"}],["path",{d:"M8 7h8",key:"i86dvs"}],["circle",{cx:"12",cy:"17",r:"5",key:"qbz8iq"}],["path",{d:"M12 18v-2h-.5",key:"fawc4q"}]]),f=m("award",[["path",{d:"m15.477 12.89 1.515 8.526a.5.5 0 0 1-.81.47l-3.58-2.687a1 1 0 0 0-1.197 0l-3.586 2.686a.5.5 0 0 1-.81-.469l1.514-8.526",key:"1yiouv"}],["circle",{cx:"12",cy:"8",r:"6",key:"1vp47v"}]]),k=(0,s.memo)(e=>{let{rank:t}=e;return(0,r.jsx)("div",{className:"rank-cell ".concat(t<=3?"top-rank":""),children:(0,r.jsxs)("div",{className:"flex items-center justify-center gap-1",children:[1===t?(0,r.jsx)(x,{className:"w-4 h-4 text-yellow-500"}):2===t?(0,r.jsx)(g,{className:"w-4 h-4 text-gray-400"}):3===t?(0,r.jsx)(f,{className:"w-4 h-4 text-amber-600"}):null,(0,r.jsx)("span",{children:t})]})})});k.displayName="RankCell";let p=(0,s.memo)(e=>{let{name:t,description:a,category:s,hardware:l}=e;return(0,r.jsxs)("div",{className:"model-info",children:[(0,r.jsx)("div",{className:"model-icon",style:{backgroundColor:{gemma3:"#3b82f6",gemma3n:"#8b5cf6","gpt-oss":"#10b981",llama3:"#f59e0b","llama3.1":"#ef4444"}[s]||"#6b7280"},children:t.charAt(0).toUpperCase()}),(0,r.jsxs)("div",{children:[(0,r.jsx)("div",{className:"model-name",children:t}),(0,r.jsx)("div",{className:"model-description",children:a})]})]})});p.displayName="ModelInfo";let S=(0,s.memo)(e=>{let{score:t}=e;return(0,r.jsx)("div",{className:"score-cell ".concat((e=>null==e?"score-na":e>=.7?"score-high":e>=.4?"score-medium":"score-low")(t)),children:null!=t?h(t):"—"})});S.displayName="ScoreCell";let b=(0,s.memo)(e=>{let{category:t}=e;return(0,r.jsx)("span",{className:"category-badge ".concat({gemma3:"badge-gemma3",gemma3n:"badge-gemma3n","gpt-oss":"badge-gpt-oss",llama3:"badge-llama3","llama3.1":"badge-llama31"}[t]||"badge-gemma3"),children:t})});function j(e){let{icon:t,title:a,description:s,children:l,gradient:c}=e;return(0,r.jsxs)("div",{className:"relative group",children:[(0,r.jsx)("div",{className:"absolute inset-0 bg-gradient-to-br from-blue-500/20 via-cyan-500/10 to-blue-600/20 rounded-xl blur-xl opacity-30 group-hover:opacity-50 transition-opacity duration-300"}),(0,r.jsxs)("div",{className:"relative bg-slate-800/90 backdrop-blur-sm border border-slate-600/50 rounded-xl shadow-xl overflow-hidden hover:shadow-2xl transition-all duration-300 group-hover:border-blue-500/30",children:[(0,r.jsx)("div",{className:"absolute inset-0 bg-gradient-to-br ".concat(c," opacity-5")}),(0,r.jsxs)("div",{className:"relative p-6",children:[(0,r.jsxs)("div",{className:"flex items-center mb-6",children:[(0,r.jsx)("div",{className:"w-12 h-12 bg-gradient-to-br ".concat(c," rounded-xl flex items-center justify-center mr-4 flex-shrink-0 shadow-lg group-hover:scale-105 transition-transform duration-300"),children:t?(0,r.jsx)("span",{className:"text-white text-xl",children:t}):(0,r.jsx)("div",{className:"w-6 h-6 bg-white/20 rounded-md"})}),(0,r.jsxs)("div",{className:"min-w-0 flex-1",children:[(0,r.jsx)("h3",{className:"text-xl font-bold text-slate-100 group-hover:text-white transition-colors duration-300",children:a}),(0,r.jsx)("p",{className:"text-slate-400 text-sm mt-1",children:s})]})]}),(0,r.jsx)("div",{className:"text-left",children:l})]}),(0,r.jsx)("div",{className:"h-1 bg-gradient-to-r ".concat(c," opacity-60")})]})]})}function _(e){let{environment:t}=e;return t.os,t.framework,t.primaryGpu,t.secondaryGpu,(0,r.jsx)(j,{icon:"",title:"",description:"",gradient:"from-blue-500 to-indigo-600",children:(0,r.jsxs)("div",{children:[(0,r.jsx)("h2",{className:"text-base font-bold text-slate-100",children:"Test Environment"}),(0,r.jsx)("div",{className:"text-slate-400 text-xs",children:"Hardware and software specifications"}),(0,r.jsxs)("div",{className:"space-y-4",children:[(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"text-sm font-bold text-blue-300",children:"OS"}),(0,r.jsx)("div",{className:"text-slate-100 font-mono text-xs",children:t.os})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"text-sm font-bold text-blue-300",children:"FW"}),(0,r.jsx)("div",{className:"text-slate-100 font-mono text-xs",children:t.framework})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"text-sm font-bold text-blue-300",children:"GPU1"}),(0,r.jsx)("div",{className:"text-slate-100 font-mono text-xs",children:t.primaryGpu})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"text-sm font-bold text-blue-300",children:"GPU2"}),(0,r.jsx)("div",{className:"text-slate-100 font-mono text-xs",children:t.secondaryGpu})]})]})]})})}function w(e){let{benchmarks:t}=e;return t.gsm8k,t.tmmluplus,(0,r.jsx)(j,{icon:"",title:"",description:"",gradient:"from-purple-500 to-pink-600",children:(0,r.jsxs)("div",{children:[(0,r.jsx)("h2",{className:"text-base font-bold text-slate-100",children:"Evaluation Benchmarks"}),(0,r.jsx)("div",{className:"text-slate-400 text-xs",children:"Comprehensive assessment methodology"}),(0,r.jsxs)("div",{className:"space-y-4",children:[(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"text-sm font-bold text-emerald-300",children:"MATH"}),(0,r.jsxs)("div",{className:"font-bold text-slate-200 text-xs",children:["GSM8K: ",t.gsm8k]})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"text-sm font-bold text-purple-300",children:"LANG"}),(0,r.jsxs)("div",{className:"font-bold text-slate-200 text-xs",children:["TMML+: ",t.tmmluplus]})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"text-sm font-bold text-amber-300",children:"METHOD"}),(0,r.jsx)("div",{className:"font-bold text-slate-200 text-xs",children:"Flexible: Lenient answer extraction from output"}),(0,r.jsx)("div",{className:"font-bold text-slate-200 text-xs",children:"Strict: Requires output to match specified format"})]})]})]})})}function y(e){let{license:t}=e;return(0,r.jsx)(j,{icon:"",title:"",description:"",gradient:"from-green-500 to-emerald-600",children:(0,r.jsxs)("div",{children:[(0,r.jsx)("h2",{className:"text-base font-bold text-slate-100",children:"License Information"}),(0,r.jsx)("div",{className:"text-slate-400 text-xs",children:"Open source licensing details"}),(0,r.jsxs)("div",{className:"space-y-4",children:[(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"text-sm font-bold text-green-300",children:"LICENSE"}),(0,r.jsx)("div",{className:"text-slate-100 font-mono text-xs",children:t.type})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"text-sm font-bold text-green-300",children:"COPYRIGHT"}),(0,r.jsxs)("div",{className:"text-slate-300 text-xs",children:[t.copyright," ",t.year," ",t.holder]})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"text-sm font-bold text-green-300",children:"TERMS"}),(0,r.jsx)("div",{className:"text-slate-400 text-xs leading-relaxed",children:"Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files."})]})]})]})})}function N(){let{data:e,stats:t,benchmark:a,category:l,framework:c,searchTerm:i,setBenchmark:n,setCategory:m,setFramework:x,setSearchTerm:g,resetFilters:f,isEmpty:j,hasFilters:N}=(()=>{let[e,t]=(0,s.useState)("gsm8k-flex"),[a,r]=(0,s.useState)("all"),[l,c]=(0,s.useState)("all"),[i,n]=(0,s.useState)(""),m=(0,s.useMemo)(()=>d.map(t=>{var a,r,s,l,c,i,n;let m=t.scores.find(e=>"gsm8k"===e.task&&"flexible-extract"===e.filter),o=t.scores.find(e=>"gsm8k"===e.task&&"strict-match"===e.filter),u=t.scores.find(e=>"tmmluplus"===e.task),d=t.scores.find(e=>"tmmluplus_STEM"===e.task),h=t.scores.find(e=>"tmmluplus_humanities"===e.task),v=t.scores.find(e=>"tmmluplus_other"===e.task),x=t.scores.find(e=>"tmmluplus_social_sciences"===e.task),g=null!=(a=null==m?void 0:m.value)?a:null,f=null!=(r=null==o?void 0:o.value)?r:null,k=null!=(s=null==u?void 0:u.value)?s:null,p=null!=(l=null==d?void 0:d.value)?l:null,S=null!=(c=null==h?void 0:h.value)?c:null,b=null!=(i=null==v?void 0:v.value)?i:null,j=null!=(n=null==x?void 0:x.value)?n:null,_=t.framework||"unknown",w=null;switch(e){case"gsm8k-flex":w=g;break;case"gsm8k-strict":w=f;break;case"tmmluplus":w=k;break;case"tmmluplus_STEM":w=p;break;case"tmmluplus_humanities":w=S;break;case"tmmluplus_other":w=b;break;case"tmmluplus_social_sciences":w=j}return{rank:0,name:t.name,description:t.description,category:t.category,score:w,allScores:{gsm8kFlex:g,gsm8kStrict:f,tmmluplus:k,tmmluplusSTEM:p,tmmluplusHumanities:S,tmmluplusOther:b,tmmluplus_social_sciences:j},hardware:t.hardware,framework:_}}).sort((e,t)=>null===e.score&&null!==t.score?1:null!==e.score&&null===t.score?-1:null===e.score&&null===t.score?0:t.score-e.score).map((e,t)=>({...e,rank:t+1})),[e]),o=(0,s.useMemo)(()=>m.filter(e=>{let t=e.name.toLowerCase().includes(i.toLowerCase()),r="all"===a||e.category===a,s="all"===l||e.framework===l;return t&&r&&s}),[m,i,a,l]),u=(0,s.useMemo)(()=>{let e=d.length,t=m.filter(e=>null!==e.score).length,a=m.filter(e=>null!==e.score).reduce((e,t)=>e+(t.score||0),0)/t,r=Math.max(...m.map(e=>e.score||0));return{totalModels:e,modelsWithCurrentScore:t,avgScore:isNaN(a)?0:a,topScore:isFinite(r)?r:0}},[m]),h=(0,s.useCallback)(e=>{t(e)},[]),v=(0,s.useCallback)(e=>{r(e)},[]),x=(0,s.useCallback)(e=>{n(e)},[]),g=(0,s.useCallback)(()=>{r("all"),c("all"),n("")},[]);return{data:o,stats:u,benchmark:e,category:a,framework:l,searchTerm:i,setBenchmark:h,setCategory:v,setFramework:(0,s.useCallback)(e=>{c(e)},[]),setSearchTerm:x,resetFilters:g,isEmpty:0===o.length,hasFilters:"all"!==a||"all"!==l||""!==i}})();return(0,r.jsxs)("div",{className:"arena-container",children:[(0,r.jsxs)("header",{className:"arena-header",children:[(0,r.jsx)("h1",{className:"arena-title",children:"LLM Benchmark Arena"}),(0,r.jsx)("p",{className:"arena-subtitle",children:"View rankings across various LLMs on their mathematical reasoning and Traditional Chinese understanding capabilities."}),(0,r.jsxs)("div",{className:"arena-stats",children:[(0,r.jsx)("span",{children:"Last Updated: Aug 16, 2025"}),(0,r.jsxs)("span",{children:["Total Models: ",t.totalModels]}),(0,r.jsxs)("span",{children:["Active Models: ",t.modelsWithCurrentScore]}),(0,r.jsxs)("span",{children:["Top Score: ",h(t.topScore)]}),(0,r.jsxs)("span",{children:["Average: ",h(t.avgScore)]})]})]}),(0,r.jsx)("div",{className:"arena-controls",children:(0,r.jsxs)("div",{className:"control-group",children:[(0,r.jsx)("div",{className:"select-wrapper",children:(0,r.jsx)("select",{value:a,onChange:e=>n(e.target.value),className:"arena-select",children:[{value:"gsm8k-flex",label:"GSM8K (Flexible)",emoji:"\uD83D\uDCCA"},{value:"gsm8k-strict",label:"GSM8K (Strict)",emoji:"\uD83D\uDCCA"},{value:"tmmluplus",label:"TMMLU+",emoji:"\uD83C\uDDF9\uD83C\uDDFC"},{value:"tmmluplus_STEM",label:"TMMLU+ STEM",emoji:"\uD83D\uDD2C"},{value:"tmmluplus_humanities",label:"TMMLU+ Humanities",emoji:"\uD83D\uDCDA"},{value:"tmmluplus_other",label:"TMMLU+ Other",emoji:"\uD83D\uDCDD"},{value:"tmmluplus_social_sciences",label:"TMMLU+ Social Sciences",emoji:"\uD83C\uDFDB️"}].map(e=>(0,r.jsx)("option",{value:e.value,children:e.label},e.value))})}),(0,r.jsx)("div",{className:"select-wrapper",children:(0,r.jsx)("select",{value:l,onChange:e=>m(e.target.value),className:"arena-select",children:[{value:"all",label:"All Categories"},{value:"gemma3",label:"Gemma3"},{value:"gemma3n",label:"Gemma3n"},{value:"gpt-oss",label:"GPT-OSS"},{value:"llama3",label:"Llama3"},{value:"llama3.1",label:"Llama3.1"}].map(e=>(0,r.jsx)("option",{value:e.value,children:e.label},e.value))})}),(0,r.jsx)("div",{className:"select-wrapper",children:(0,r.jsx)("select",{value:c,onChange:e=>x(e.target.value),className:"arena-select",children:[{value:"all",label:"All Frameworks",emoji:"\uD83D\uDD27"},{value:"huggingface",label:"Hugging Face",emoji:"\uD83E\uDD17"},{value:"ollama",label:"Ollama",emoji:"\uD83E\uDD99"},{value:"llama.cpp",label:"llama.cpp",emoji:"⚡"}].map(e=>(0,r.jsxs)("option",{value:e.value,children:[e.emoji," ",e.label]},e.value))})}),(0,r.jsxs)("div",{className:"search-container",children:[(0,r.jsx)(o,{className:"search-icon"}),(0,r.jsx)("input",{type:"text",placeholder:"Search by model name...",value:i,onChange:e=>g(e.target.value),className:"search-input"})]}),N&&(0,r.jsxs)("button",{onClick:f,className:"reset-button",title:"Reset filters",children:[(0,r.jsx)(u,{className:"w-4 h-4"}),"Reset"]})]})}),N&&(0,r.jsxs)("div",{className:"px-4 py-2 text-sm text-slate-400",children:["Showing ",e.length," of ",t.totalModels," models",i&&' matching "'.concat(i,'"'),"all"!==l&&" in ".concat(l)]}),(0,r.jsx)("div",{className:"arena-table-container",children:j?(0,r.jsxs)("div",{className:"p-8 text-center",children:[(0,r.jsx)("div",{className:"text-slate-500 mb-2",children:"No models found"}),(0,r.jsx)("div",{className:"text-sm text-slate-400",children:"Try adjusting your search criteria or filters"})]}):(0,r.jsxs)("table",{className:"arena-table",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{children:[(0,r.jsx)("th",{children:"Rank"}),(0,r.jsx)("th",{children:"Model"}),(0,r.jsx)("th",{children:"Score"}),(0,r.jsx)("th",{children:"Category"}),(0,r.jsx)("th",{children:"Hardware"})]})}),(0,r.jsx)("tbody",{children:e.map(e=>(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:(0,r.jsx)(k,{rank:e.rank})}),(0,r.jsx)("td",{children:(0,r.jsx)(p,{name:e.name,description:e.description,category:e.category,hardware:e.hardware})}),(0,r.jsx)("td",{children:(0,r.jsx)(S,{score:e.score})}),(0,r.jsx)("td",{children:(0,r.jsx)(b,{category:e.category})}),(0,r.jsx)("td",{className:"text-center",children:e.hardware?(0,r.jsx)("span",{className:"text-xs bg-red-500/20 text-red-400 px-2 py-1 rounded",children:e.hardware}):(0,r.jsx)("span",{className:"text-gray-500",children:"RTX4090"})})]},e.name))})]})}),(0,r.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6 mt-8",children:[(0,r.jsx)(_,{environment:v.environment}),(0,r.jsx)(w,{benchmarks:v.benchmarks}),(0,r.jsx)(y,{license:v.license})]})]})}b.displayName="CategoryBadge"},8774:(e,t,a)=>{Promise.resolve().then(a.bind(a,5747))}},e=>{e.O(0,[441,964,358],()=>e(e.s=8774)),_N_E=e.O()}]);