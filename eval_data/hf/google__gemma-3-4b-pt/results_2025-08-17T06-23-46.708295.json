{
  "results": {
    "gsm8k": {
      "alias": "gsm8k",
      "exact_match,strict-match": 0.37225170583775585,
      "exact_match_stderr,strict-match": 0.013315375362565038,
      "exact_match,flexible-extract": 0.37452615617892343,
      "exact_match_stderr,flexible-extract": 0.013331774158491384
    },
    "tmmluplus": {
      "acc,none": 0.3748015873015873,
      "acc_stderr,none": 0.003369815844399701,
      "acc_norm,none": 0.3748015873015873,
      "acc_norm_stderr,none": 0.003369815844399701,
      "alias": "tmmluplus"
    },
    "tmmluplus_STEM": {
      "acc,none": 0.36942857142857144,
      "acc_stderr,none": 0.008079038279183059,
      "acc_norm,none": 0.36942857142857144,
      "acc_norm_stderr,none": 0.008079038279183059,
      "alias": " - tmmluplus_STEM"
    },
    "tmmluplus_advance_chemistry": {
      "alias": "  - advance chemistry",
      "acc,none": 0.3170731707317073,
      "acc_stderr,none": 0.04212955964853051,
      "acc_norm,none": 0.3170731707317073,
      "acc_norm_stderr,none": 0.04212955964853051
    },
    "tmmluplus_basic_medical_science": {
      "alias": "  - basic medical science",
      "acc,none": 0.3668763102725367,
      "acc_stderr,none": 0.015611968504344296,
      "acc_norm,none": 0.3668763102725367,
      "acc_norm_stderr,none": 0.015611968504344296
    },
    "tmmluplus_computer_science": {
      "alias": "  - computer science",
      "acc,none": 0.4942528735632184,
      "acc_stderr,none": 0.03801178479702085,
      "acc_norm,none": 0.4942528735632184,
      "acc_norm_stderr,none": 0.03801178479702085
    },
    "tmmluplus_engineering_math": {
      "alias": "  - engineering math",
      "acc,none": 0.33980582524271846,
      "acc_stderr,none": 0.046897659372781335,
      "acc_norm,none": 0.33980582524271846,
      "acc_norm_stderr,none": 0.046897659372781335
    },
    "tmmluplus_junior_chemistry": {
      "alias": "  - junior chemistry",
      "acc,none": 0.3684210526315789,
      "acc_stderr,none": 0.033446784700118,
      "acc_norm,none": 0.3684210526315789,
      "acc_norm_stderr,none": 0.033446784700118
    },
    "tmmluplus_junior_math_exam": {
      "alias": "  - junior math exam",
      "acc,none": 0.32571428571428573,
      "acc_stderr,none": 0.03552759084811122,
      "acc_norm,none": 0.32571428571428573,
      "acc_norm_stderr,none": 0.03552759084811122
    },
    "tmmluplus_junior_science_exam": {
      "alias": "  - junior science exam",
      "acc,none": 0.4225352112676056,
      "acc_stderr,none": 0.033925501519258806,
      "acc_norm,none": 0.4225352112676056,
      "acc_norm_stderr,none": 0.033925501519258806
    },
    "tmmluplus_linear_algebra": {
      "alias": "  - linear algebra",
      "acc,none": 0.38095238095238093,
      "acc_stderr,none": 0.07584124375059005,
      "acc_norm,none": 0.38095238095238093,
      "acc_norm_stderr,none": 0.07584124375059005
    },
    "tmmluplus_organic_chemistry": {
      "alias": "  - organic chemistry",
      "acc,none": 0.3761467889908257,
      "acc_stderr,none": 0.04661310240641662,
      "acc_norm,none": 0.3761467889908257,
      "acc_norm_stderr,none": 0.04661310240641662
    },
    "tmmluplus_pharmacy": {
      "alias": "  - pharmacy",
      "acc,none": 0.23017902813299232,
      "acc_stderr,none": 0.021315495936701692,
      "acc_norm,none": 0.23017902813299232,
      "acc_norm_stderr,none": 0.021315495936701692
    },
    "tmmluplus_physics": {
      "alias": "  - physics",
      "acc,none": 0.31958762886597936,
      "acc_stderr,none": 0.04759326111499844,
      "acc_norm,none": 0.31958762886597936,
      "acc_norm_stderr,none": 0.04759326111499844
    },
    "tmmluplus_secondary_physics": {
      "alias": "  - secondary physics",
      "acc,none": 0.36607142857142855,
      "acc_stderr,none": 0.04572372358737431,
      "acc_norm,none": 0.36607142857142855,
      "acc_norm_stderr,none": 0.04572372358737431
    },
    "tmmluplus_statistics_and_machine_learning": {
      "alias": "  - statistics and machine learning",
      "acc,none": 0.45535714285714285,
      "acc_stderr,none": 0.03334874933322443,
      "acc_norm,none": 0.45535714285714285,
      "acc_norm_stderr,none": 0.03334874933322443
    },
    "tmmluplus_tve_mathematics": {
      "alias": "  - tve mathematics",
      "acc,none": 0.26666666666666666,
      "acc_stderr,none": 0.03622779862191886,
      "acc_norm,none": 0.26666666666666666,
      "acc_norm_stderr,none": 0.03622779862191886
    },
    "tmmluplus_tve_natural_sciences": {
      "alias": "  - tve natural sciences",
      "acc,none": 0.4669811320754717,
      "acc_stderr,none": 0.024257764439559563,
      "acc_norm,none": 0.4669811320754717,
      "acc_norm_stderr,none": 0.024257764439559563
    },
    "tmmluplus_humanities": {
      "acc,none": 0.32671582529778787,
      "acc_stderr,none": 0.011026563399222476,
      "acc_norm,none": 0.32671582529778787,
      "acc_norm_stderr,none": 0.011026563399222476,
      "alias": " - tmmluplus_humanities"
    },
    "tmmluplus_administrative_law": {
      "alias": "  - administrative law",
      "acc,none": 0.2833333333333333,
      "acc_stderr,none": 0.022014074232932706,
      "acc_norm,none": 0.2833333333333333,
      "acc_norm_stderr,none": 0.022014074232932706
    },
    "tmmluplus_anti_money_laundering": {
      "alias": "  - anti money laundering",
      "acc,none": 0.5447761194029851,
      "acc_stderr,none": 0.04318130157253041,
      "acc_norm,none": 0.5447761194029851,
      "acc_norm_stderr,none": 0.04318130157253041
    },
    "tmmluplus_general_principles_of_law": {
      "alias": "  - general principles of law",
      "acc,none": 0.39622641509433965,
      "acc_stderr,none": 0.047732492983673595,
      "acc_norm,none": 0.39622641509433965,
      "acc_norm_stderr,none": 0.047732492983673595
    },
    "tmmluplus_introduction_to_law": {
      "alias": "  - introduction to law",
      "acc,none": 0.33755274261603374,
      "acc_stderr,none": 0.030781549102026216,
      "acc_norm,none": 0.33755274261603374,
      "acc_norm_stderr,none": 0.030781549102026216
    },
    "tmmluplus_jce_humanities": {
      "alias": "  - jce humanities",
      "acc,none": 0.45555555555555555,
      "acc_stderr,none": 0.05279009646630345,
      "acc_norm,none": 0.45555555555555555,
      "acc_norm_stderr,none": 0.05279009646630345
    },
    "tmmluplus_taxation": {
      "alias": "  - taxation",
      "acc,none": 0.25066666666666665,
      "acc_stderr,none": 0.02241042113925442,
      "acc_norm,none": 0.25066666666666665,
      "acc_norm_stderr,none": 0.02241042113925442
    },
    "tmmluplus_trust_practice": {
      "alias": "  - trust practice",
      "acc,none": 0.3167082294264339,
      "acc_stderr,none": 0.02325962848155608,
      "acc_norm,none": 0.3167082294264339,
      "acc_norm_stderr,none": 0.02325962848155608
    },
    "tmmluplus_other": {
      "acc,none": 0.3660364694037364,
      "acc_stderr,none": 0.005051945632445054,
      "acc_norm,none": 0.3660364694037364,
      "acc_norm_stderr,none": 0.005051945632445054,
      "alias": " - tmmluplus_other"
    },
    "tmmluplus_accounting": {
      "alias": "  - accounting",
      "acc,none": 0.23036649214659685,
      "acc_stderr,none": 0.030547441226520554,
      "acc_norm,none": 0.23036649214659685,
      "acc_norm_stderr,none": 0.030547441226520554
    },
    "tmmluplus_agriculture": {
      "alias": "  - agriculture",
      "acc,none": 0.2847682119205298,
      "acc_stderr,none": 0.03684881521389024,
      "acc_norm,none": 0.2847682119205298,
      "acc_norm_stderr,none": 0.03684881521389024
    },
    "tmmluplus_auditing": {
      "alias": "  - auditing",
      "acc,none": 0.2909090909090909,
      "acc_stderr,none": 0.019384001427930078,
      "acc_norm,none": 0.2909090909090909,
      "acc_norm_stderr,none": 0.019384001427930078
    },
    "tmmluplus_business_management": {
      "alias": "  - business management",
      "acc,none": 0.49640287769784175,
      "acc_stderr,none": 0.04256172505827059,
      "acc_norm,none": 0.49640287769784175,
      "acc_norm_stderr,none": 0.04256172505827059
    },
    "tmmluplus_culinary_skills": {
      "alias": "  - culinary skills",
      "acc,none": 0.4931506849315068,
      "acc_stderr,none": 0.029307768863382593,
      "acc_norm,none": 0.4931506849315068,
      "acc_norm_stderr,none": 0.029307768863382593
    },
    "tmmluplus_dentistry": {
      "alias": "  - dentistry",
      "acc,none": 0.42857142857142855,
      "acc_stderr,none": 0.024805674864567095,
      "acc_norm,none": 0.42857142857142855,
      "acc_norm_stderr,none": 0.024805674864567095
    },
    "tmmluplus_finance_banking": {
      "alias": "  - finance banking",
      "acc,none": 0.3111111111111111,
      "acc_stderr,none": 0.03999262876617722,
      "acc_norm,none": 0.3111111111111111,
      "acc_norm_stderr,none": 0.03999262876617722
    },
    "tmmluplus_financial_analysis": {
      "alias": "  - financial analysis",
      "acc,none": 0.337696335078534,
      "acc_stderr,none": 0.024228652716881002,
      "acc_norm,none": 0.337696335078534,
      "acc_norm_stderr,none": 0.024228652716881002
    },
    "tmmluplus_fire_science": {
      "alias": "  - fire science",
      "acc,none": 0.31451612903225806,
      "acc_stderr,none": 0.0418665838391958,
      "acc_norm,none": 0.31451612903225806,
      "acc_norm_stderr,none": 0.0418665838391958
    },
    "tmmluplus_insurance_studies": {
      "alias": "  - insurance studies",
      "acc,none": 0.3460526315789474,
      "acc_stderr,none": 0.01726718684222519,
      "acc_norm,none": 0.3460526315789474,
      "acc_norm_stderr,none": 0.01726718684222519
    },
    "tmmluplus_junior_social_studies": {
      "alias": "  - junior social studies",
      "acc,none": 0.48412698412698413,
      "acc_stderr,none": 0.04469881854072606,
      "acc_norm,none": 0.48412698412698413,
      "acc_norm_stderr,none": 0.04469881854072606
    },
    "tmmluplus_logic_reasoning": {
      "alias": "  - logic reasoning",
      "acc,none": 0.2517985611510791,
      "acc_stderr,none": 0.03694846055443905,
      "acc_norm,none": 0.2517985611510791,
      "acc_norm_stderr,none": 0.03694846055443905
    },
    "tmmluplus_management_accounting": {
      "alias": "  - management accounting",
      "acc,none": 0.31627906976744186,
      "acc_stderr,none": 0.03178833470533975,
      "acc_norm,none": 0.31627906976744186,
      "acc_norm_stderr,none": 0.03178833470533975
    },
    "tmmluplus_marketing_management": {
      "alias": "  - marketing management",
      "acc,none": 0.46236559139784944,
      "acc_stderr,none": 0.051980729214439164,
      "acc_norm,none": 0.46236559139784944,
      "acc_norm_stderr,none": 0.051980729214439164
    },
    "tmmluplus_mechanical": {
      "alias": "  - mechanical",
      "acc,none": 0.5423728813559322,
      "acc_stderr,none": 0.046058726812661495,
      "acc_norm,none": 0.5423728813559322,
      "acc_norm_stderr,none": 0.046058726812661495
    },
    "tmmluplus_music": {
      "alias": "  - music",
      "acc,none": 0.4028776978417266,
      "acc_stderr,none": 0.029469880507468366,
      "acc_norm,none": 0.4028776978417266,
      "acc_norm_stderr,none": 0.029469880507468366
    },
    "tmmluplus_nautical_science": {
      "alias": "  - nautical science",
      "acc,none": 0.3430127041742287,
      "acc_stderr,none": 0.0202419451521885,
      "acc_norm,none": 0.3430127041742287,
      "acc_norm_stderr,none": 0.0202419451521885
    },
    "tmmluplus_official_document_management": {
      "alias": "  - official document management",
      "acc,none": 0.35135135135135137,
      "acc_stderr,none": 0.032112893285729936,
      "acc_norm,none": 0.35135135135135137,
      "acc_norm_stderr,none": 0.032112893285729936
    },
    "tmmluplus_optometry": {
      "alias": "  - optometry",
      "acc,none": 0.34456521739130436,
      "acc_stderr,none": 0.015676268888439798,
      "acc_norm,none": 0.34456521739130436,
      "acc_norm_stderr,none": 0.015676268888439798
    },
    "tmmluplus_pharmacology": {
      "alias": "  - pharmacology",
      "acc,none": 0.41421143847487,
      "acc_stderr,none": 0.020524389400489736,
      "acc_norm,none": 0.41421143847487,
      "acc_norm_stderr,none": 0.020524389400489736
    },
    "tmmluplus_real_estate": {
      "alias": "  - real estate",
      "acc,none": 0.31521739130434784,
      "acc_stderr,none": 0.04870356481341373,
      "acc_norm,none": 0.31521739130434784,
      "acc_norm_stderr,none": 0.04870356481341373
    },
    "tmmluplus_technical": {
      "alias": "  - technical",
      "acc,none": 0.4577114427860697,
      "acc_stderr,none": 0.02487934365032028,
      "acc_norm,none": 0.4577114427860697,
      "acc_norm_stderr,none": 0.02487934365032028
    },
    "tmmluplus_trade": {
      "alias": "  - trade",
      "acc,none": 0.27689243027888444,
      "acc_stderr,none": 0.019991166329253275,
      "acc_norm,none": 0.27689243027888444,
      "acc_norm_stderr,none": 0.019991166329253275
    },
    "tmmluplus_traditional_chinese_medicine_clinical_medicine": {
      "alias": "  - traditional chinese medicine clinical medicine",
      "acc,none": 0.32014388489208634,
      "acc_stderr,none": 0.028031169980276147,
      "acc_norm,none": 0.32014388489208634,
      "acc_norm_stderr,none": 0.028031169980276147
    },
    "tmmluplus_tve_design": {
      "alias": "  - tve design",
      "acc,none": 0.43333333333333335,
      "acc_stderr,none": 0.022641600614887684,
      "acc_norm,none": 0.43333333333333335,
      "acc_norm_stderr,none": 0.022641600614887684
    },
    "tmmluplus_veterinary_pathology": {
      "alias": "  - veterinary pathology",
      "acc,none": 0.31448763250883394,
      "acc_stderr,none": 0.027649346978285274,
      "acc_norm,none": 0.31448763250883394,
      "acc_norm_stderr,none": 0.027649346978285274
    },
    "tmmluplus_veterinary_pharmacology": {
      "alias": "  - veterinary pharmacology",
      "acc,none": 0.4148148148148148,
      "acc_stderr,none": 0.021221662726503953,
      "acc_norm,none": 0.4148148148148148,
      "acc_norm_stderr,none": 0.021221662726503953
    },
    "tmmluplus_social_sciences": {
      "acc,none": 0.405337361530715,
      "acc_stderr,none": 0.006276382491520932,
      "acc_norm,none": 0.405337361530715,
      "acc_norm_stderr,none": 0.006276382491520932,
      "alias": " - tmmluplus_social_sciences"
    },
    "tmmluplus_chinese_language_and_literature": {
      "alias": "  - chinese language and literature",
      "acc,none": 0.2814070351758794,
      "acc_stderr,none": 0.03195776219152244,
      "acc_norm,none": 0.2814070351758794,
      "acc_norm_stderr,none": 0.03195776219152244
    },
    "tmmluplus_clinical_psychology": {
      "alias": "  - clinical psychology",
      "acc,none": 0.44,
      "acc_stderr,none": 0.04457686366483794,
      "acc_norm,none": 0.44,
      "acc_norm_stderr,none": 0.04457686366483794
    },
    "tmmluplus_economics": {
      "alias": "  - economics",
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.02380952380952386,
      "acc_norm,none": 0.3333333333333333,
      "acc_norm_stderr,none": 0.02380952380952386
    },
    "tmmluplus_education": {
      "alias": "  - education",
      "acc,none": 0.4435483870967742,
      "acc_stderr,none": 0.04479521746037352,
      "acc_norm,none": 0.4435483870967742,
      "acc_norm_stderr,none": 0.04479521746037352
    },
    "tmmluplus_education_(profession_level)": {
      "alias": "  - education (profession level)",
      "acc,none": 0.28600823045267487,
      "acc_stderr,none": 0.02051941612913057,
      "acc_norm,none": 0.28600823045267487,
      "acc_norm_stderr,none": 0.02051941612913057
    },
    "tmmluplus_educational_psychology": {
      "alias": "  - educational psychology",
      "acc,none": 0.4659090909090909,
      "acc_stderr,none": 0.037708491648233415,
      "acc_norm,none": 0.4659090909090909,
      "acc_norm_stderr,none": 0.037708491648233415
    },
    "tmmluplus_geography_of_taiwan": {
      "alias": "  - geography of taiwan",
      "acc,none": 0.4296875,
      "acc_stderr,none": 0.017874550252590944,
      "acc_norm,none": 0.4296875,
      "acc_norm_stderr,none": 0.017874550252590944
    },
    "tmmluplus_human_behavior": {
      "alias": "  - human behavior",
      "acc,none": 0.4563106796116505,
      "acc_stderr,none": 0.028381174211497842,
      "acc_norm,none": 0.4563106796116505,
      "acc_norm_stderr,none": 0.028381174211497842
    },
    "tmmluplus_junior_chinese_exam": {
      "alias": "  - junior chinese exam",
      "acc,none": 0.4742857142857143,
      "acc_stderr,none": 0.03785474169043359,
      "acc_norm,none": 0.4742857142857143,
      "acc_norm_stderr,none": 0.03785474169043359
    },
    "tmmluplus_macroeconomics": {
      "alias": "  - macroeconomics",
      "acc,none": 0.3284671532846715,
      "acc_stderr,none": 0.023194642069369845,
      "acc_norm,none": 0.3284671532846715,
      "acc_norm_stderr,none": 0.023194642069369845
    },
    "tmmluplus_national_protection": {
      "alias": "  - national protection",
      "acc,none": 0.5213270142180095,
      "acc_stderr,none": 0.034471876630125575,
      "acc_norm,none": 0.5213270142180095,
      "acc_norm_stderr,none": 0.034471876630125575
    },
    "tmmluplus_occupational_therapy_for_psychological_disorders": {
      "alias": "  - occupational therapy for psychological disorders",
      "acc,none": 0.47513812154696133,
      "acc_stderr,none": 0.021450272321265118,
      "acc_norm,none": 0.47513812154696133,
      "acc_norm_stderr,none": 0.021450272321265118
    },
    "tmmluplus_physical_education": {
      "alias": "  - physical education",
      "acc,none": 0.3687150837988827,
      "acc_stderr,none": 0.036161643250458134,
      "acc_norm,none": 0.3687150837988827,
      "acc_norm_stderr,none": 0.036161643250458134
    },
    "tmmluplus_politic_science": {
      "alias": "  - politic science",
      "acc,none": 0.3597989949748744,
      "acc_stderr,none": 0.015222814545479536,
      "acc_norm,none": 0.3597989949748744,
      "acc_norm_stderr,none": 0.015222814545479536
    },
    "tmmluplus_taiwanese_hokkien": {
      "alias": "  - taiwanese hokkien",
      "acc,none": 0.2558139534883721,
      "acc_stderr,none": 0.03856540453901632,
      "acc_norm,none": 0.2558139534883721,
      "acc_norm_stderr,none": 0.03856540453901632
    },
    "tmmluplus_three_principles_of_people": {
      "alias": "  - three principles of people",
      "acc,none": 0.5899280575539568,
      "acc_stderr,none": 0.04186875148834218,
      "acc_norm,none": 0.5899280575539568,
      "acc_norm_stderr,none": 0.04186875148834218
    },
    "tmmluplus_ttqav2": {
      "alias": "  - ttqav2",
      "acc,none": 0.6548672566371682,
      "acc_stderr,none": 0.04492216809001807,
      "acc_norm,none": 0.6548672566371682,
      "acc_norm_stderr,none": 0.04492216809001807
    },
    "tmmluplus_tve_chinese_language": {
      "alias": "  - tve chinese language",
      "acc,none": 0.4699792960662526,
      "acc_stderr,none": 0.02273328839192925,
      "acc_norm,none": 0.4699792960662526,
      "acc_norm_stderr,none": 0.02273328839192925
    }
  },
  "groups": {
    "tmmluplus": {
      "acc,none": 0.3748015873015873,
      "acc_stderr,none": 0.003369815844399701,
      "acc_norm,none": 0.3748015873015873,
      "acc_norm_stderr,none": 0.003369815844399701,
      "alias": "tmmluplus"
    },
    "tmmluplus_STEM": {
      "acc,none": 0.36942857142857144,
      "acc_stderr,none": 0.008079038279183059,
      "acc_norm,none": 0.36942857142857144,
      "acc_norm_stderr,none": 0.008079038279183059,
      "alias": " - tmmluplus_STEM"
    },
    "tmmluplus_humanities": {
      "acc,none": 0.32671582529778787,
      "acc_stderr,none": 0.011026563399222476,
      "acc_norm,none": 0.32671582529778787,
      "acc_norm_stderr,none": 0.011026563399222476,
      "alias": " - tmmluplus_humanities"
    },
    "tmmluplus_other": {
      "acc,none": 0.3660364694037364,
      "acc_stderr,none": 0.005051945632445054,
      "acc_norm,none": 0.3660364694037364,
      "acc_norm_stderr,none": 0.005051945632445054,
      "alias": " - tmmluplus_other"
    },
    "tmmluplus_social_sciences": {
      "acc,none": 0.405337361530715,
      "acc_stderr,none": 0.006276382491520932,
      "acc_norm,none": 0.405337361530715,
      "acc_norm_stderr,none": 0.006276382491520932,
      "alias": " - tmmluplus_social_sciences"
    }
  },
  "group_subtasks": {
    "gsm8k": [],
    "tmmluplus_STEM": [
      "tmmluplus_pharmacy",
      "tmmluplus_advance_chemistry",
      "tmmluplus_junior_math_exam",
      "tmmluplus_tve_mathematics",
      "tmmluplus_junior_chemistry",
      "tmmluplus_basic_medical_science",
      "tmmluplus_statistics_and_machine_learning",
      "tmmluplus_engineering_math",
      "tmmluplus_junior_science_exam",
      "tmmluplus_physics",
      "tmmluplus_linear_algebra",
      "tmmluplus_secondary_physics",
      "tmmluplus_tve_natural_sciences",
      "tmmluplus_organic_chemistry",
      "tmmluplus_computer_science"
    ],
    "tmmluplus_humanities": [
      "tmmluplus_general_principles_of_law",
      "tmmluplus_anti_money_laundering",
      "tmmluplus_administrative_law",
      "tmmluplus_trust_practice",
      "tmmluplus_jce_humanities",
      "tmmluplus_introduction_to_law",
      "tmmluplus_taxation"
    ],
    "tmmluplus_social_sciences": [
      "tmmluplus_national_protection",
      "tmmluplus_education_(profession_level)",
      "tmmluplus_occupational_therapy_for_psychological_disorders",
      "tmmluplus_tve_chinese_language",
      "tmmluplus_clinical_psychology",
      "tmmluplus_three_principles_of_people",
      "tmmluplus_macroeconomics",
      "tmmluplus_geography_of_taiwan",
      "tmmluplus_taiwanese_hokkien",
      "tmmluplus_politic_science",
      "tmmluplus_human_behavior",
      "tmmluplus_educational_psychology",
      "tmmluplus_chinese_language_and_literature",
      "tmmluplus_economics",
      "tmmluplus_junior_chinese_exam",
      "tmmluplus_education",
      "tmmluplus_physical_education",
      "tmmluplus_ttqav2"
    ],
    "tmmluplus_other": [
      "tmmluplus_optometry",
      "tmmluplus_veterinary_pharmacology",
      "tmmluplus_marketing_management",
      "tmmluplus_business_management",
      "tmmluplus_traditional_chinese_medicine_clinical_medicine",
      "tmmluplus_music",
      "tmmluplus_nautical_science",
      "tmmluplus_accounting",
      "tmmluplus_logic_reasoning",
      "tmmluplus_official_document_management",
      "tmmluplus_mechanical",
      "tmmluplus_dentistry",
      "tmmluplus_junior_social_studies",
      "tmmluplus_technical",
      "tmmluplus_fire_science",
      "tmmluplus_culinary_skills",
      "tmmluplus_real_estate",
      "tmmluplus_auditing",
      "tmmluplus_pharmacology",
      "tmmluplus_trade",
      "tmmluplus_tve_design",
      "tmmluplus_finance_banking",
      "tmmluplus_agriculture",
      "tmmluplus_veterinary_pathology",
      "tmmluplus_management_accounting",
      "tmmluplus_insurance_studies",
      "tmmluplus_financial_analysis"
    ],
    "tmmluplus": [
      "tmmluplus_other",
      "tmmluplus_social_sciences",
      "tmmluplus_humanities",
      "tmmluplus_STEM"
    ]
  },
  "configs": {
    "gsm8k": {
      "task": "gsm8k",
      "tag": [
        "math_word_problems"
      ],
      "dataset_path": "gsm8k",
      "dataset_name": "main",
      "training_split": "train",
      "test_split": "test",
      "fewshot_split": "train",
      "doc_to_text": "Question: {{question}}\nAnswer:",
      "doc_to_target": "{{answer}}",
      "unsafe_code": false,
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "exact_match",
          "aggregation": "mean",
          "higher_is_better": true,
          "ignore_case": true,
          "ignore_punctuation": false,
          "regexes_to_ignore": [
            ",",
            "\\$",
            "(?s).*#### ",
            "\\.$"
          ]
        }
      ],
      "output_type": "generate_until",
      "generation_kwargs": {
        "until": [
          "Question:",
          "</s>",
          "<|im_end|>"
        ],
        "do_sample": false,
        "temperature": 0.0
      },
      "repeats": 1,
      "filter_list": [
        {
          "name": "strict-match",
          "filter": [
            {
              "function": "regex",
              "regex_pattern": "#### (\\-?[0-9\\.\\,]+)"
            },
            {
              "function": "take_first"
            }
          ]
        },
        {
          "name": "flexible-extract",
          "filter": [
            {
              "function": "regex",
              "group_select": -1,
              "regex_pattern": "(-?[$0-9.,]{2,})|(-?[0-9]+)"
            },
            {
              "function": "take_first"
            }
          ]
        }
      ],
      "should_decontaminate": false,
      "metadata": {
        "version": 3.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_accounting": {
      "task": "tmmluplus_accounting",
      "task_alias": "accounting",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "accounting",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為會計學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_administrative_law": {
      "task": "tmmluplus_administrative_law",
      "task_alias": "administrative law",
      "tag": "tmmluplus_humanities_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "administrative_law",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為行政法的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_advance_chemistry": {
      "task": "tmmluplus_advance_chemistry",
      "task_alias": "advance chemistry",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "advance_chemistry",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為化學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_agriculture": {
      "task": "tmmluplus_agriculture",
      "task_alias": "agriculture",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "agriculture",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為農業的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_anti_money_laundering": {
      "task": "tmmluplus_anti_money_laundering",
      "task_alias": "anti money laundering",
      "tag": "tmmluplus_humanities_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "anti_money_laundering",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為洗錢防制的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_auditing": {
      "task": "tmmluplus_auditing",
      "task_alias": "auditing",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "auditing",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為審計學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_basic_medical_science": {
      "task": "tmmluplus_basic_medical_science",
      "task_alias": "basic medical science",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "basic_medical_science",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為基礎醫學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_business_management": {
      "task": "tmmluplus_business_management",
      "task_alias": "business management",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "business_management",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為企業管理的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_chinese_language_and_literature": {
      "task": "tmmluplus_chinese_language_and_literature",
      "task_alias": "chinese language and literature",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "chinese_language_and_literature",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為國文的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_clinical_psychology": {
      "task": "tmmluplus_clinical_psychology",
      "task_alias": "clinical psychology",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "clinical_psychology",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為臨床心理學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_computer_science": {
      "task": "tmmluplus_computer_science",
      "task_alias": "computer science",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "computer_science",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為資訊工程的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_culinary_skills": {
      "task": "tmmluplus_culinary_skills",
      "task_alias": "culinary skills",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "culinary_skills",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為餐旅的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_dentistry": {
      "task": "tmmluplus_dentistry",
      "task_alias": "dentistry",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "dentistry",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為牙醫學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_economics": {
      "task": "tmmluplus_economics",
      "task_alias": "economics",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "economics",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為經濟學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_education": {
      "task": "tmmluplus_education",
      "task_alias": "education",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "education",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為教育常識的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_education_(profession_level)": {
      "task": "tmmluplus_education_(profession_level)",
      "task_alias": "education (profession level)",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "education_(profession_level)",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為教育專業的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_educational_psychology": {
      "task": "tmmluplus_educational_psychology",
      "task_alias": "educational psychology",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "educational_psychology",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為教育心理的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_engineering_math": {
      "task": "tmmluplus_engineering_math",
      "task_alias": "engineering math",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "engineering_math",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為工程數學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_finance_banking": {
      "task": "tmmluplus_finance_banking",
      "task_alias": "finance banking",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "finance_banking",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為金融與法規的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_financial_analysis": {
      "task": "tmmluplus_financial_analysis",
      "task_alias": "financial analysis",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "financial_analysis",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為財務分析的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_fire_science": {
      "task": "tmmluplus_fire_science",
      "task_alias": "fire science",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "fire_science",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為火災學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_general_principles_of_law": {
      "task": "tmmluplus_general_principles_of_law",
      "task_alias": "general principles of law",
      "tag": "tmmluplus_humanities_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "general_principles_of_law",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為法學大意的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_geography_of_taiwan": {
      "task": "tmmluplus_geography_of_taiwan",
      "task_alias": "geography of taiwan",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "geography_of_taiwan",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為台灣地理的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_human_behavior": {
      "task": "tmmluplus_human_behavior",
      "task_alias": "human behavior",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "human_behavior",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為人類行為與社會的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_insurance_studies": {
      "task": "tmmluplus_insurance_studies",
      "task_alias": "insurance studies",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "insurance_studies",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為保險學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_introduction_to_law": {
      "task": "tmmluplus_introduction_to_law",
      "task_alias": "introduction to law",
      "tag": "tmmluplus_humanities_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "introduction_to_law",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為法律概論的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_jce_humanities": {
      "task": "tmmluplus_jce_humanities",
      "task_alias": "jce humanities",
      "tag": "tmmluplus_humanities_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "jce_humanities",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為指考人文科目的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_junior_chemistry": {
      "task": "tmmluplus_junior_chemistry",
      "task_alias": "junior chemistry",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "junior_chemistry",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為國中理化的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_junior_chinese_exam": {
      "task": "tmmluplus_junior_chinese_exam",
      "task_alias": "junior chinese exam",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "junior_chinese_exam",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為國中會考基測國文的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_junior_math_exam": {
      "task": "tmmluplus_junior_math_exam",
      "task_alias": "junior math exam",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "junior_math_exam",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為國中會考基測數學科的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_junior_science_exam": {
      "task": "tmmluplus_junior_science_exam",
      "task_alias": "junior science exam",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "junior_science_exam",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為國中會考基測自然科的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_junior_social_studies": {
      "task": "tmmluplus_junior_social_studies",
      "task_alias": "junior social studies",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "junior_social_studies",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為國中會考基測社會科的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_linear_algebra": {
      "task": "tmmluplus_linear_algebra",
      "task_alias": "linear algebra",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "linear_algebra",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為線代的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_logic_reasoning": {
      "task": "tmmluplus_logic_reasoning",
      "task_alias": "logic reasoning",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "logic_reasoning",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為邏輯思維的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_macroeconomics": {
      "task": "tmmluplus_macroeconomics",
      "task_alias": "macroeconomics",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "macroeconomics",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為總經的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_management_accounting": {
      "task": "tmmluplus_management_accounting",
      "task_alias": "management accounting",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "management_accounting",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為管理會計的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_marketing_management": {
      "task": "tmmluplus_marketing_management",
      "task_alias": "marketing management",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "marketing_management",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為行銷管理的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_mechanical": {
      "task": "tmmluplus_mechanical",
      "task_alias": "mechanical",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "mechanical",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為機械與機電概論的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_music": {
      "task": "tmmluplus_music",
      "task_alias": "music",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "music",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為音樂科的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_national_protection": {
      "task": "tmmluplus_national_protection",
      "task_alias": "national protection",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "national_protection",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為軍事的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_nautical_science": {
      "task": "tmmluplus_nautical_science",
      "task_alias": "nautical science",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "nautical_science",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為航海的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_occupational_therapy_for_psychological_disorders": {
      "task": "tmmluplus_occupational_therapy_for_psychological_disorders",
      "task_alias": "occupational therapy for psychological disorders",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "occupational_therapy_for_psychological_disorders",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為心理障礙職能治療學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_official_document_management": {
      "task": "tmmluplus_official_document_management",
      "task_alias": "official document management",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "official_document_management",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為機關文書的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_optometry": {
      "task": "tmmluplus_optometry",
      "task_alias": "optometry",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "optometry",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為視光學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_organic_chemistry": {
      "task": "tmmluplus_organic_chemistry",
      "task_alias": "organic chemistry",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "organic_chemistry",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為有機化學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_pharmacology": {
      "task": "tmmluplus_pharmacology",
      "task_alias": "pharmacology",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "pharmacology",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為藥理學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_pharmacy": {
      "task": "tmmluplus_pharmacy",
      "task_alias": "pharmacy",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "pharmacy",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為藥劑學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_physical_education": {
      "task": "tmmluplus_physical_education",
      "task_alias": "physical education",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "physical_education",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為體育的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_physics": {
      "task": "tmmluplus_physics",
      "task_alias": "physics",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "physics",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為物理的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_politic_science": {
      "task": "tmmluplus_politic_science",
      "task_alias": "politic science",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "politic_science",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為政治的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_real_estate": {
      "task": "tmmluplus_real_estate",
      "task_alias": "real estate",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "real_estate",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為房地產的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_secondary_physics": {
      "task": "tmmluplus_secondary_physics",
      "task_alias": "secondary physics",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "secondary_physics",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為高中物理的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_statistics_and_machine_learning": {
      "task": "tmmluplus_statistics_and_machine_learning",
      "task_alias": "statistics and machine learning",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "statistics_and_machine_learning",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為統計與機器學習的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_taiwanese_hokkien": {
      "task": "tmmluplus_taiwanese_hokkien",
      "task_alias": "taiwanese hokkien",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "taiwanese_hokkien",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為閩南語的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_taxation": {
      "task": "tmmluplus_taxation",
      "task_alias": "taxation",
      "tag": "tmmluplus_humanities_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "taxation",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為稅務的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_technical": {
      "task": "tmmluplus_technical",
      "task_alias": "technical",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "technical",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為技術工相關的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_three_principles_of_people": {
      "task": "tmmluplus_three_principles_of_people",
      "task_alias": "three principles of people",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "three_principles_of_people",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為三民主義的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_trade": {
      "task": "tmmluplus_trade",
      "task_alias": "trade",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "trade",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為貿易的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_traditional_chinese_medicine_clinical_medicine": {
      "task": "tmmluplus_traditional_chinese_medicine_clinical_medicine",
      "task_alias": "traditional chinese medicine clinical medicine",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "traditional_chinese_medicine_clinical_medicine",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為中醫臨床醫學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_trust_practice": {
      "task": "tmmluplus_trust_practice",
      "task_alias": "trust practice",
      "tag": "tmmluplus_humanities_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "trust_practice",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為信託實務的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_ttqav2": {
      "task": "tmmluplus_ttqav2",
      "task_alias": "ttqav2",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "ttqav2",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為台灣在地用語的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_tve_chinese_language": {
      "task": "tmmluplus_tve_chinese_language",
      "task_alias": "tve chinese language",
      "tag": "tmmluplus_social_sciences_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "tve_chinese_language",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為統測國文的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_tve_design": {
      "task": "tmmluplus_tve_design",
      "task_alias": "tve design",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "tve_design",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為統測 設計的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_tve_mathematics": {
      "task": "tmmluplus_tve_mathematics",
      "task_alias": "tve mathematics",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "tve_mathematics",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為統測數學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_tve_natural_sciences": {
      "task": "tmmluplus_tve_natural_sciences",
      "task_alias": "tve natural sciences",
      "tag": "tmmluplus_STEM_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "tve_natural_sciences",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為統測自然科的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_veterinary_pathology": {
      "task": "tmmluplus_veterinary_pathology",
      "task_alias": "veterinary pathology",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "veterinary_pathology",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為獸醫病理學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    },
    "tmmluplus_veterinary_pharmacology": {
      "task": "tmmluplus_veterinary_pharmacology",
      "task_alias": "veterinary pharmacology",
      "tag": "tmmluplus_other_tasks",
      "dataset_path": "ZoneTwelve/tmmluplus",
      "dataset_name": "veterinary_pharmacology",
      "test_split": "test",
      "fewshot_split": "train",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _helper(doc):\n        # modifies the contents of a single\n        # document in our dataset.\n        answer_list = [\"A\", \"B\", \"C\", \"D\"]\n        out_doc = {\n            \"questions\": doc[\"question\"],\n            \"choices\": [doc[\"A\"], doc[\"B\"], doc[\"C\"], doc[\"D\"]],\n            \"goal\": answer_list.index(doc[\"answer\"]),\n        }\n        return out_doc\n\n    return dataset.map(_helper)  # returns back a datasets.Dataset object\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "以下為獸醫藥理學的單選題，請提供正確答案的選項。\n\n",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 2.0,
        "pretrained": "google/gemma-3-4b-pt",
        "dtype": "bfloat16",
        "max_length": 85000
      }
    }
  },
  "versions": {
    "gsm8k": 3.0,
    "tmmluplus": 2.0,
    "tmmluplus_STEM": 2.0,
    "tmmluplus_accounting": 2.0,
    "tmmluplus_administrative_law": 2.0,
    "tmmluplus_advance_chemistry": 2.0,
    "tmmluplus_agriculture": 2.0,
    "tmmluplus_anti_money_laundering": 2.0,
    "tmmluplus_auditing": 2.0,
    "tmmluplus_basic_medical_science": 2.0,
    "tmmluplus_business_management": 2.0,
    "tmmluplus_chinese_language_and_literature": 2.0,
    "tmmluplus_clinical_psychology": 2.0,
    "tmmluplus_computer_science": 2.0,
    "tmmluplus_culinary_skills": 2.0,
    "tmmluplus_dentistry": 2.0,
    "tmmluplus_economics": 2.0,
    "tmmluplus_education": 2.0,
    "tmmluplus_education_(profession_level)": 2.0,
    "tmmluplus_educational_psychology": 2.0,
    "tmmluplus_engineering_math": 2.0,
    "tmmluplus_finance_banking": 2.0,
    "tmmluplus_financial_analysis": 2.0,
    "tmmluplus_fire_science": 2.0,
    "tmmluplus_general_principles_of_law": 2.0,
    "tmmluplus_geography_of_taiwan": 2.0,
    "tmmluplus_human_behavior": 2.0,
    "tmmluplus_humanities": 2.0,
    "tmmluplus_insurance_studies": 2.0,
    "tmmluplus_introduction_to_law": 2.0,
    "tmmluplus_jce_humanities": 2.0,
    "tmmluplus_junior_chemistry": 2.0,
    "tmmluplus_junior_chinese_exam": 2.0,
    "tmmluplus_junior_math_exam": 2.0,
    "tmmluplus_junior_science_exam": 2.0,
    "tmmluplus_junior_social_studies": 2.0,
    "tmmluplus_linear_algebra": 2.0,
    "tmmluplus_logic_reasoning": 2.0,
    "tmmluplus_macroeconomics": 2.0,
    "tmmluplus_management_accounting": 2.0,
    "tmmluplus_marketing_management": 2.0,
    "tmmluplus_mechanical": 2.0,
    "tmmluplus_music": 2.0,
    "tmmluplus_national_protection": 2.0,
    "tmmluplus_nautical_science": 2.0,
    "tmmluplus_occupational_therapy_for_psychological_disorders": 2.0,
    "tmmluplus_official_document_management": 2.0,
    "tmmluplus_optometry": 2.0,
    "tmmluplus_organic_chemistry": 2.0,
    "tmmluplus_other": 2.0,
    "tmmluplus_pharmacology": 2.0,
    "tmmluplus_pharmacy": 2.0,
    "tmmluplus_physical_education": 2.0,
    "tmmluplus_physics": 2.0,
    "tmmluplus_politic_science": 2.0,
    "tmmluplus_real_estate": 2.0,
    "tmmluplus_secondary_physics": 2.0,
    "tmmluplus_social_sciences": 2.0,
    "tmmluplus_statistics_and_machine_learning": 2.0,
    "tmmluplus_taiwanese_hokkien": 2.0,
    "tmmluplus_taxation": 2.0,
    "tmmluplus_technical": 2.0,
    "tmmluplus_three_principles_of_people": 2.0,
    "tmmluplus_trade": 2.0,
    "tmmluplus_traditional_chinese_medicine_clinical_medicine": 2.0,
    "tmmluplus_trust_practice": 2.0,
    "tmmluplus_ttqav2": 2.0,
    "tmmluplus_tve_chinese_language": 2.0,
    "tmmluplus_tve_design": 2.0,
    "tmmluplus_tve_mathematics": 2.0,
    "tmmluplus_tve_natural_sciences": 2.0,
    "tmmluplus_veterinary_pathology": 2.0,
    "tmmluplus_veterinary_pharmacology": 2.0
  },
  "n-shot": {
    "gsm8k": 5,
    "tmmluplus_accounting": 0,
    "tmmluplus_administrative_law": 0,
    "tmmluplus_advance_chemistry": 0,
    "tmmluplus_agriculture": 0,
    "tmmluplus_anti_money_laundering": 0,
    "tmmluplus_auditing": 0,
    "tmmluplus_basic_medical_science": 0,
    "tmmluplus_business_management": 0,
    "tmmluplus_chinese_language_and_literature": 0,
    "tmmluplus_clinical_psychology": 0,
    "tmmluplus_computer_science": 0,
    "tmmluplus_culinary_skills": 0,
    "tmmluplus_dentistry": 0,
    "tmmluplus_economics": 0,
    "tmmluplus_education": 0,
    "tmmluplus_education_(profession_level)": 0,
    "tmmluplus_educational_psychology": 0,
    "tmmluplus_engineering_math": 0,
    "tmmluplus_finance_banking": 0,
    "tmmluplus_financial_analysis": 0,
    "tmmluplus_fire_science": 0,
    "tmmluplus_general_principles_of_law": 0,
    "tmmluplus_geography_of_taiwan": 0,
    "tmmluplus_human_behavior": 0,
    "tmmluplus_insurance_studies": 0,
    "tmmluplus_introduction_to_law": 0,
    "tmmluplus_jce_humanities": 0,
    "tmmluplus_junior_chemistry": 0,
    "tmmluplus_junior_chinese_exam": 0,
    "tmmluplus_junior_math_exam": 0,
    "tmmluplus_junior_science_exam": 0,
    "tmmluplus_junior_social_studies": 0,
    "tmmluplus_linear_algebra": 0,
    "tmmluplus_logic_reasoning": 0,
    "tmmluplus_macroeconomics": 0,
    "tmmluplus_management_accounting": 0,
    "tmmluplus_marketing_management": 0,
    "tmmluplus_mechanical": 0,
    "tmmluplus_music": 0,
    "tmmluplus_national_protection": 0,
    "tmmluplus_nautical_science": 0,
    "tmmluplus_occupational_therapy_for_psychological_disorders": 0,
    "tmmluplus_official_document_management": 0,
    "tmmluplus_optometry": 0,
    "tmmluplus_organic_chemistry": 0,
    "tmmluplus_pharmacology": 0,
    "tmmluplus_pharmacy": 0,
    "tmmluplus_physical_education": 0,
    "tmmluplus_physics": 0,
    "tmmluplus_politic_science": 0,
    "tmmluplus_real_estate": 0,
    "tmmluplus_secondary_physics": 0,
    "tmmluplus_statistics_and_machine_learning": 0,
    "tmmluplus_taiwanese_hokkien": 0,
    "tmmluplus_taxation": 0,
    "tmmluplus_technical": 0,
    "tmmluplus_three_principles_of_people": 0,
    "tmmluplus_trade": 0,
    "tmmluplus_traditional_chinese_medicine_clinical_medicine": 0,
    "tmmluplus_trust_practice": 0,
    "tmmluplus_ttqav2": 0,
    "tmmluplus_tve_chinese_language": 0,
    "tmmluplus_tve_design": 0,
    "tmmluplus_tve_mathematics": 0,
    "tmmluplus_tve_natural_sciences": 0,
    "tmmluplus_veterinary_pathology": 0,
    "tmmluplus_veterinary_pharmacology": 0
  },
  "higher_is_better": {
    "gsm8k": {
      "exact_match": true
    },
    "tmmluplus": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_STEM": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_accounting": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_administrative_law": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_advance_chemistry": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_agriculture": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_anti_money_laundering": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_auditing": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_basic_medical_science": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_business_management": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_chinese_language_and_literature": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_clinical_psychology": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_computer_science": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_culinary_skills": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_dentistry": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_economics": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_education": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_education_(profession_level)": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_educational_psychology": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_engineering_math": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_finance_banking": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_financial_analysis": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_fire_science": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_general_principles_of_law": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_geography_of_taiwan": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_human_behavior": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_humanities": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_insurance_studies": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_introduction_to_law": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_jce_humanities": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_junior_chemistry": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_junior_chinese_exam": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_junior_math_exam": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_junior_science_exam": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_junior_social_studies": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_linear_algebra": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_logic_reasoning": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_macroeconomics": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_management_accounting": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_marketing_management": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_mechanical": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_music": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_national_protection": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_nautical_science": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_occupational_therapy_for_psychological_disorders": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_official_document_management": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_optometry": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_organic_chemistry": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_other": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_pharmacology": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_pharmacy": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_physical_education": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_physics": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_politic_science": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_real_estate": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_secondary_physics": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_social_sciences": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_statistics_and_machine_learning": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_taiwanese_hokkien": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_taxation": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_technical": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_three_principles_of_people": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_trade": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_traditional_chinese_medicine_clinical_medicine": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_trust_practice": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_ttqav2": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_tve_chinese_language": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_tve_design": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_tve_mathematics": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_tve_natural_sciences": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_veterinary_pathology": {
      "acc": true,
      "acc_norm": true
    },
    "tmmluplus_veterinary_pharmacology": {
      "acc": true,
      "acc_norm": true
    }
  },
  "n-samples": {
    "tmmluplus_optometry": {
      "original": 920,
      "effective": 920
    },
    "tmmluplus_veterinary_pharmacology": {
      "original": 540,
      "effective": 540
    },
    "tmmluplus_marketing_management": {
      "original": 93,
      "effective": 93
    },
    "tmmluplus_business_management": {
      "original": 139,
      "effective": 139
    },
    "tmmluplus_traditional_chinese_medicine_clinical_medicine": {
      "original": 278,
      "effective": 278
    },
    "tmmluplus_music": {
      "original": 278,
      "effective": 278
    },
    "tmmluplus_nautical_science": {
      "original": 551,
      "effective": 551
    },
    "tmmluplus_accounting": {
      "original": 191,
      "effective": 191
    },
    "tmmluplus_logic_reasoning": {
      "original": 139,
      "effective": 139
    },
    "tmmluplus_official_document_management": {
      "original": 222,
      "effective": 222
    },
    "tmmluplus_mechanical": {
      "original": 118,
      "effective": 118
    },
    "tmmluplus_dentistry": {
      "original": 399,
      "effective": 399
    },
    "tmmluplus_junior_social_studies": {
      "original": 126,
      "effective": 126
    },
    "tmmluplus_technical": {
      "original": 402,
      "effective": 402
    },
    "tmmluplus_fire_science": {
      "original": 124,
      "effective": 124
    },
    "tmmluplus_culinary_skills": {
      "original": 292,
      "effective": 292
    },
    "tmmluplus_real_estate": {
      "original": 92,
      "effective": 92
    },
    "tmmluplus_auditing": {
      "original": 550,
      "effective": 550
    },
    "tmmluplus_pharmacology": {
      "original": 577,
      "effective": 577
    },
    "tmmluplus_trade": {
      "original": 502,
      "effective": 502
    },
    "tmmluplus_tve_design": {
      "original": 480,
      "effective": 480
    },
    "tmmluplus_finance_banking": {
      "original": 135,
      "effective": 135
    },
    "tmmluplus_agriculture": {
      "original": 151,
      "effective": 151
    },
    "tmmluplus_veterinary_pathology": {
      "original": 283,
      "effective": 283
    },
    "tmmluplus_management_accounting": {
      "original": 215,
      "effective": 215
    },
    "tmmluplus_insurance_studies": {
      "original": 760,
      "effective": 760
    },
    "tmmluplus_financial_analysis": {
      "original": 382,
      "effective": 382
    },
    "tmmluplus_national_protection": {
      "original": 211,
      "effective": 211
    },
    "tmmluplus_education_(profession_level)": {
      "original": 486,
      "effective": 486
    },
    "tmmluplus_occupational_therapy_for_psychological_disorders": {
      "original": 543,
      "effective": 543
    },
    "tmmluplus_tve_chinese_language": {
      "original": 483,
      "effective": 483
    },
    "tmmluplus_clinical_psychology": {
      "original": 125,
      "effective": 125
    },
    "tmmluplus_three_principles_of_people": {
      "original": 139,
      "effective": 139
    },
    "tmmluplus_macroeconomics": {
      "original": 411,
      "effective": 411
    },
    "tmmluplus_geography_of_taiwan": {
      "original": 768,
      "effective": 768
    },
    "tmmluplus_taiwanese_hokkien": {
      "original": 129,
      "effective": 129
    },
    "tmmluplus_politic_science": {
      "original": 995,
      "effective": 995
    },
    "tmmluplus_human_behavior": {
      "original": 309,
      "effective": 309
    },
    "tmmluplus_educational_psychology": {
      "original": 176,
      "effective": 176
    },
    "tmmluplus_chinese_language_and_literature": {
      "original": 199,
      "effective": 199
    },
    "tmmluplus_economics": {
      "original": 393,
      "effective": 393
    },
    "tmmluplus_junior_chinese_exam": {
      "original": 175,
      "effective": 175
    },
    "tmmluplus_education": {
      "original": 124,
      "effective": 124
    },
    "tmmluplus_physical_education": {
      "original": 179,
      "effective": 179
    },
    "tmmluplus_ttqav2": {
      "original": 113,
      "effective": 113
    },
    "tmmluplus_general_principles_of_law": {
      "original": 106,
      "effective": 106
    },
    "tmmluplus_anti_money_laundering": {
      "original": 134,
      "effective": 134
    },
    "tmmluplus_administrative_law": {
      "original": 420,
      "effective": 420
    },
    "tmmluplus_trust_practice": {
      "original": 401,
      "effective": 401
    },
    "tmmluplus_jce_humanities": {
      "original": 90,
      "effective": 90
    },
    "tmmluplus_introduction_to_law": {
      "original": 237,
      "effective": 237
    },
    "tmmluplus_taxation": {
      "original": 375,
      "effective": 375
    },
    "tmmluplus_pharmacy": {
      "original": 391,
      "effective": 391
    },
    "tmmluplus_advance_chemistry": {
      "original": 123,
      "effective": 123
    },
    "tmmluplus_junior_math_exam": {
      "original": 175,
      "effective": 175
    },
    "tmmluplus_tve_mathematics": {
      "original": 150,
      "effective": 150
    },
    "tmmluplus_junior_chemistry": {
      "original": 209,
      "effective": 209
    },
    "tmmluplus_basic_medical_science": {
      "original": 954,
      "effective": 954
    },
    "tmmluplus_statistics_and_machine_learning": {
      "original": 224,
      "effective": 224
    },
    "tmmluplus_engineering_math": {
      "original": 103,
      "effective": 103
    },
    "tmmluplus_junior_science_exam": {
      "original": 213,
      "effective": 213
    },
    "tmmluplus_physics": {
      "original": 97,
      "effective": 97
    },
    "tmmluplus_linear_algebra": {
      "original": 42,
      "effective": 42
    },
    "tmmluplus_secondary_physics": {
      "original": 112,
      "effective": 112
    },
    "tmmluplus_tve_natural_sciences": {
      "original": 424,
      "effective": 424
    },
    "tmmluplus_organic_chemistry": {
      "original": 109,
      "effective": 109
    },
    "tmmluplus_computer_science": {
      "original": 174,
      "effective": 174
    },
    "gsm8k": {
      "original": 1319,
      "effective": 1319
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=google/gemma-3-4b-pt,dtype=bfloat16,max_length=85000",
    "model_num_parameters": 4300079472,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "cc012e0a6d0787b4adcc0fa2c4da74402494554d",
    "batch_size": "1",
    "batch_sizes": [],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": {
      "do_sample": false
    },
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "3bc7cc8a",
  "date": 1755408735.3917797,
  "pretty_env_info": "PyTorch version: 2.8.0+cu128\nIs debug build: False\nCUDA used to build PyTorch: 12.8\nROCM used to build PyTorch: N/A\n\nOS: Ubuntu 22.04.5 LTS (x86_64)\nGCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\nClang version: 14.0.0-1ubuntu1.1\nCMake version: version 3.22.1\nLibc version: glibc-2.35\n\nPython version: 3.10.12 (main, May 27 2025, 17:12:29) [GCC 11.4.0] (64-bit runtime)\nPython platform: Linux-5.15.0-151-generic-x86_64-with-glibc2.35\nIs CUDA available: True\nCUDA runtime version: Could not collect\nCUDA_MODULE_LOADING set to: LAZY\nGPU models and configuration: GPU 0: NVIDIA GeForce RTX 4090\nNvidia driver version: 580.65.06\ncuDNN version: Could not collect\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:                            x86_64\nCPU op-mode(s):                          32-bit, 64-bit\nAddress sizes:                           46 bits physical, 48 bits virtual\nByte Order:                              Little Endian\nCPU(s):                                  8\nOn-line CPU(s) list:                     0-7\nVendor ID:                               GenuineIntel\nModel name:                              Intel(R) Core(TM) i5-14500\nCPU family:                              6\nModel:                                   191\nThread(s) per core:                      1\nCore(s) per socket:                      8\nSocket(s):                               1\nStepping:                                2\nBogoMIPS:                                5222.40\nFlags:                                   fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves avx_vnni arat umip pku ospke waitpkg gfni vaes vpclmulqdq rdpid movdiri movdir64b fsrm md_clear serialize flush_l1d arch_capabilities\nVirtualization:                          VT-x\nHypervisor vendor:                       KVM\nVirtualization type:                     full\nL1d cache:                               256 KiB (8 instances)\nL1i cache:                               256 KiB (8 instances)\nL2 cache:                                32 MiB (8 instances)\nL3 cache:                                16 MiB (1 instance)\nNUMA node(s):                            1\nNUMA node0 CPU(s):                       0-7\nVulnerability Gather data sampling:      Not affected\nVulnerability Indirect target selection: Not affected\nVulnerability Itlb multihit:             Not affected\nVulnerability L1tf:                      Not affected\nVulnerability Mds:                       Not affected\nVulnerability Meltdown:                  Not affected\nVulnerability Mmio stale data:           Not affected\nVulnerability Reg file data sampling:    Mitigation; Clear Register File\nVulnerability Retbleed:                  Not affected\nVulnerability Spec rstack overflow:      Not affected\nVulnerability Spec store bypass:         Mitigation; Speculative Store Bypass disabled via prctl and seccomp\nVulnerability Spectre v1:                Mitigation; usercopy/swapgs barriers and __user pointer sanitization\nVulnerability Spectre v2:                Mitigation; Enhanced / Automatic IBRS; IBPB conditional; PBRSB-eIBRS SW sequence; BHI BHI_DIS_S\nVulnerability Srbds:                     Not affected\nVulnerability Tsx async abort:           Not affected\n\nVersions of relevant libraries:\n[pip3] Could not collect\n[conda] Could not collect",
  "transformers_version": "4.55.2",
  "lm_eval_version": "0.4.9.1",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<pad>",
    "0"
  ],
  "tokenizer_eos_token": [
    "<eos>",
    "1"
  ],
  "tokenizer_bos_token": [
    "<bos>",
    "2"
  ],
  "eot_token_id": 1,
  "max_length": 85000,
  "task_hashes": {},
  "model_source": "hf",
  "model_name": "google/gemma-3-4b-pt",
  "model_name_sanitized": "google__gemma-3-4b-pt",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": null,
  "chat_template_sha": null,
  "start_time": 144263.591641637,
  "end_time": 147356.394808829,
  "total_evaluation_time_seconds": "3092.8031671920035"
}